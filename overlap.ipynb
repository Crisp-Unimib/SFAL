{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3bdd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layers:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer 0...\n",
      "Processing embedding model: Alibaba-NLP/gte-Qwen2-7B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Alibaba-NLP/gte-Qwen2-7B-instruct for layer 0\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B_new for layer 0\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B for layer 0\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-0.6B for layer 0\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-4B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-4B for layer 0\n",
      "Processing embedding model: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layers:  20%|██        | 1/5 [05:13<20:55, 313.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Lajavaness/bilingual-embedding-large for layer 0\n",
      "\n",
      "Processing layer 8...\n",
      "Processing embedding model: Alibaba-NLP/gte-Qwen2-7B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Alibaba-NLP/gte-Qwen2-7B-instruct for layer 8\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B_new for layer 8\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B for layer 8\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-0.6B for layer 8\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-4B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-4B for layer 8\n",
      "Processing embedding model: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layers:  40%|████      | 2/5 [10:40<16:04, 321.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Lajavaness/bilingual-embedding-large for layer 8\n",
      "\n",
      "Processing layer 17...\n",
      "Processing embedding model: Alibaba-NLP/gte-Qwen2-7B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Alibaba-NLP/gte-Qwen2-7B-instruct for layer 17\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B_new for layer 17\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B for layer 17\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-0.6B for layer 17\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-4B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-4B for layer 17\n",
      "Processing embedding model: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layers:  60%|██████    | 3/5 [16:15<10:54, 327.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Lajavaness/bilingual-embedding-large for layer 17\n",
      "\n",
      "Processing layer 25...\n",
      "Processing embedding model: Alibaba-NLP/gte-Qwen2-7B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Alibaba-NLP/gte-Qwen2-7B-instruct for layer 25\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B_new for layer 25\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B for layer 25\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-0.6B for layer 25\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-4B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-4B for layer 25\n",
      "Processing embedding model: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layers:  80%|████████  | 4/5 [21:44<05:28, 328.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Lajavaness/bilingual-embedding-large for layer 25\n",
      "\n",
      "Processing layer 31...\n",
      "Processing embedding model: Alibaba-NLP/gte-Qwen2-7B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Alibaba-NLP/gte-Qwen2-7B-instruct for layer 31\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B_new for layer 31\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-8B for layer 31\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-0.6B for layer 31\n",
      "Processing embedding model: Qwen/Qwen3-Embedding-4B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Qwen/Qwen3-Embedding-4B for layer 31\n",
      "Processing embedding model: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layers: 100%|██████████| 5/5 [27:13<00:00, 326.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding Lajavaness/bilingual-embedding-large for layer 31\n",
      "\n",
      "Results saved to: /home/mmezzanzanica/project/scoring_autoint_align/3_analysis/no_reranked_ndcg_all_layers_llama_with_all_overlaps.csv\n",
      "Final dataset shape: (100, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "# Directory where your embeddings are stored\n",
    "LAYER_BASE_PATH = \"/home/mmezzanzanica/project/scoring_autoint_align/data/Llama3_1-8B-Base-LXR-8x\"\n",
    "PKL_FILE_NAME = \"oai_token-act-pair_gpt-4o-mini_embeddings.pkl\"\n",
    "NPZ_PATH_TEMPLATE = LAYER_BASE_PATH + \"/{layer}-llamascope-res-32k/pajama_meta-llama_Llama-3.1-8B_res_Llama3_1-8B-Base-L{layer}R-8x_checkpoints_final.safetensors_docs100k_keq512_cooccurrences.npz\"\n",
    "\n",
    "TOP_N_FEATURES = 1023\n",
    "N_TOTAL_CHUNKS = 71687\n",
    "EXPECTED_TOTAL_ROWS = 32768\n",
    "EMBEDDING_COL_NAME = 'embedding'\n",
    "\n",
    "def find_embedding_models(layer_path):\n",
    "    \"\"\"Recursively find all PKL files in all subdirs, return (embedding_model_path_relative_to_layer, full_path) tuples.\"\"\"\n",
    "    layer_dir = Path(layer_path)\n",
    "    embedding_models = []\n",
    "    for pkl_path in layer_dir.rglob(\"oai_token-act-pair_gpt-4o-mini_embeddings.pkl\"):\n",
    "        # Get the path relative to layer_dir to use as the model identifier\n",
    "        rel_path = pkl_path.parent.relative_to(layer_dir)\n",
    "        emb_name = str(rel_path)  # e.g., 'Alibaba-NLP/gte-Qwen2-7B-instruct'\n",
    "        embedding_models.append((emb_name, str(pkl_path)))\n",
    "    return embedding_models\n",
    "\n",
    "\n",
    "def load_and_prepare_dataframe(pkl_path, npz_path, expected_rows=None):\n",
    "    try:\n",
    "        df = pd.read_pickle(pkl_path)\n",
    "        if expected_rows is not None and expected_rows > 0:\n",
    "            if not pd.api.types.is_numeric_dtype(df['index']):\n",
    "                raise TypeError(\"The 'index' column is not numeric.\")\n",
    "            full_index_range = set(range(expected_rows))\n",
    "            existing_indices = set(df['index'])\n",
    "            missing_indices = sorted(list(full_index_range - existing_indices))\n",
    "            if missing_indices:\n",
    "                first_valid_embedding = df['embedding'].dropna().iloc[0]\n",
    "                embedding_dim = len(first_valid_embedding)\n",
    "                null_embedding = np.zeros(embedding_dim, dtype=np.array(first_valid_embedding).dtype)\n",
    "                rows_to_add = [{'index': idx, 'embedding': null_embedding} for idx in missing_indices]\n",
    "                if rows_to_add:\n",
    "                    new_rows_df = pd.DataFrame(rows_to_add)\n",
    "                    df = pd.concat([df, new_rows_df], ignore_index=True)\n",
    "                    df = df.sort_values(by='index').reset_index(drop=True)\n",
    "        with np.load(npz_path) as data:\n",
    "            key_to_use = data.files[0]\n",
    "            cooc_embeddings_matrix = data[key_to_use]\n",
    "        if len(df) != cooc_embeddings_matrix.shape[0]:\n",
    "            raise ValueError(f\"Shape mismatch: DataFrame has {len(df)} rows, but co-occurrence matrix has {cooc_embeddings_matrix.shape[0]} rows.\")\n",
    "        df['cooc_embedding'] = list(cooc_embeddings_matrix)\n",
    "        return df, cooc_embeddings_matrix\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calculate_phi_coefficient(n_ii, n_jj, n_ij, N):\n",
    "    n_ii, n_jj, n_ij, N = float(n_ii), float(n_jj), float(n_ij), float(N)\n",
    "    if N == 0:\n",
    "        return 0.0\n",
    "    n11 = n_ij\n",
    "    n10 = n_ii - n_ij\n",
    "    n01 = n_jj - n_ij\n",
    "    n00 = max(0.0, N - n_ii - n_jj + n_ij)\n",
    "    ni_dot = n_ii\n",
    "    n_dot_j = n_jj\n",
    "    n0_dot = N - ni_dot\n",
    "    n_dot_0 = N - n_dot_j\n",
    "    try:\n",
    "        denominator = math.sqrt(ni_dot * n_dot_j * n0_dot * n_dot_0)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "    if denominator == 0:\n",
    "        if n11 == ni_dot and n11 == n_dot_j and n00 == 0:\n",
    "            return 1.0\n",
    "        if n10 == ni_dot and n01 == n_dot_j and n11 == 0:\n",
    "            return -1.0\n",
    "        return 0.0\n",
    "    numerator = (n11 * n00) - (n10 * n01)\n",
    "    phi = numerator / denominator\n",
    "    return np.clip(phi, -1.0, 1.0)\n",
    "\n",
    "def get_most_phi_correlated_features(ref_idx, df_input, cooc_mat, N_total, top_n=10):\n",
    "    if ref_idx < 0 or ref_idx >= len(df_input):\n",
    "        raise IndexError(f\"Reference index {ref_idx} is out of bounds.\")\n",
    "    occurrence_counts = np.diag(cooc_mat).astype(np.float32)\n",
    "    cooc_mat_float = cooc_mat.astype(np.float32)\n",
    "    ref_n_ii = occurrence_counts[ref_idx]\n",
    "    if ref_n_ii == 0:\n",
    "        return pd.DataFrame({'id': [], 'phi': []})\n",
    "    phi_scores = []\n",
    "    indices = []\n",
    "    for j in range(len(df_input)):\n",
    "        if j == ref_idx:\n",
    "            continue\n",
    "        n_jj = occurrence_counts[j]\n",
    "        n_ij = cooc_mat_float[ref_idx, j]\n",
    "        phi_score = calculate_phi_coefficient(ref_n_ii, n_jj, n_ij, N_total)\n",
    "        phi_scores.append(phi_score)\n",
    "        indices.append(df_input.index[j])\n",
    "    df_scores = pd.DataFrame({'id': indices, 'phi': phi_scores})\n",
    "    return df_scores.sort_values(by='phi', ascending=False).head(top_n)\n",
    "\n",
    "def get_most_semantically_similar_features(ref_idx, df_input, embedding_column, top_n=10):\n",
    "    if ref_idx < 0 or ref_idx >= len(df_input):\n",
    "        raise IndexError(f\"Reference index {ref_idx} is out of bounds.\")\n",
    "    if embedding_column not in df_input.columns:\n",
    "        raise ValueError(f\"DataFrame must contain the embedding column: '{embedding_column}'.\")\n",
    "    embeddings_np = np.stack(df_input[embedding_column].values).astype(np.float32)\n",
    "    ref_embedding = embeddings_np[ref_idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(ref_embedding, embeddings_np)[0]\n",
    "    similarities[ref_idx] = -np.inf\n",
    "    sorted_indices = np.argsort(-similarities)\n",
    "    top_n_indices = sorted_indices[:top_n]\n",
    "    df_similar = pd.DataFrame({\n",
    "        'id': df_input.index[top_n_indices],\n",
    "        'cosine': similarities[top_n_indices]\n",
    "    })\n",
    "    return df_similar\n",
    "\n",
    "def calculate_overlap_for_feature(row, df_layer, cooc_matrix):\n",
    "    try:\n",
    "        ref_feature_index = row['index']\n",
    "        df_similar_phi = get_most_phi_correlated_features(\n",
    "            ref_feature_index, df_layer, cooc_matrix, N_TOTAL_CHUNKS, top_n=TOP_N_FEATURES\n",
    "        )\n",
    "        df_similar_emb = get_most_semantically_similar_features(\n",
    "            ref_feature_index, df_layer, EMBEDDING_COL_NAME, top_n=TOP_N_FEATURES\n",
    "        )\n",
    "        if len(df_similar_phi) == 0 or len(df_similar_emb) == 0:\n",
    "            return 0\n",
    "        df_common = pd.merge(df_similar_emb, df_similar_phi, on='id')\n",
    "        overlap_count = len(df_common)\n",
    "        return overlap_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing feature {row['index']}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def sanitize_emb_col(emb_name):\n",
    "    # sanitize name for column (replace /, space, etc)\n",
    "    return emb_name.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "def main():\n",
    "    data_llama = pd.read_csv('/home/mmezzanzanica/project/scoring_autoint_align/3_analysis/eval/llama/no_rerank_llama_debug_eval.csv')\n",
    "    unique_layers = data_llama['layer'].unique()\n",
    "    for layer in tqdm(unique_layers, desc=\"Processing layers\"):\n",
    "        print(f\"\\nProcessing layer {layer}...\")\n",
    "        layer_dir = os.path.join(LAYER_BASE_PATH, f\"{layer}-llamascope-res-32k\")\n",
    "        npz_path = NPZ_PATH_TEMPLATE.format(layer=layer)\n",
    "        if not os.path.exists(layer_dir):\n",
    "            print(f\"Layer dir not found: {layer_dir}\")\n",
    "            continue\n",
    "        if not os.path.exists(npz_path):\n",
    "            print(f\"NPZ file not found for layer {layer}: {npz_path}\")\n",
    "            continue\n",
    "        embedding_models = find_embedding_models(layer_dir)\n",
    "        if not embedding_models:\n",
    "            print(f\"No embedding models found in {layer_dir}\")\n",
    "            continue\n",
    "        for emb_name, emb_pkl_path in embedding_models:\n",
    "            print(f\"Processing embedding model: {emb_name}\")\n",
    "            if not os.path.exists(emb_pkl_path):\n",
    "                print(f\"Embedding PKL not found: {emb_pkl_path}\")\n",
    "                continue\n",
    "            df_layer, cooc_matrix = load_and_prepare_dataframe(emb_pkl_path, npz_path, EXPECTED_TOTAL_ROWS)\n",
    "            if df_layer is None or cooc_matrix is None:\n",
    "                print(f\"Skipping embedding model {emb_name} for layer {layer} due to error.\")\n",
    "                continue\n",
    "            emb_col = f\"overlap_{sanitize_emb_col(emb_name)}\"\n",
    "            # Filter main df for this layer and ensure the 'index' values match\n",
    "            layer_mask = data_llama['layer'] == layer\n",
    "            for idx, row in tqdm(data_llama[layer_mask].iterrows(), total=layer_mask.sum(),\n",
    "                                 desc=f\"Layer {layer} - {emb_name}\", leave=False):\n",
    "                overlap_count = calculate_overlap_for_feature(row, df_layer, cooc_matrix)\n",
    "                data_llama.at[idx, emb_col] = overlap_count\n",
    "            print(f\"Completed embedding {emb_name} for layer {layer}\")\n",
    "    # Save results\n",
    "    output_path = '/home/mmezzanzanica/project/scoring_autoint_align/3_analysis/no_reranked_ndcg_all_layers_llama_with_all_overlaps.csv'\n",
    "    data_llama.to_csv(output_path, index=False)\n",
    "    print(f\"\\nResults saved to: {output_path}\")\n",
    "    print(f\"Final dataset shape: {data_llama.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32047cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>layer</th>\n",
       "      <th>url</th>\n",
       "      <th>media_antonio</th>\n",
       "      <th>media_daniele</th>\n",
       "      <th>media_andrea</th>\n",
       "      <th>media_filippo</th>\n",
       "      <th>mean_vote</th>\n",
       "      <th>score_gemini-2.0-flash</th>\n",
       "      <th>ndcg_Lajavaness/bilingual-embedding-large</th>\n",
       "      <th>...</th>\n",
       "      <th>ndcg_Qwen/Qwen3-Embedding-8B_new</th>\n",
       "      <th>ndcg_Qwen/Qwen3-Embedding-8B</th>\n",
       "      <th>ndcg_Qwen/Qwen3-Embedding-0.6B</th>\n",
       "      <th>ndcg_Qwen/Qwen3-Embedding-4B</th>\n",
       "      <th>overlap_Alibaba-NLP_gte-Qwen2-7B-instruct</th>\n",
       "      <th>overlap_Qwen_Qwen3-Embedding-8B_new</th>\n",
       "      <th>overlap_Qwen_Qwen3-Embedding-8B</th>\n",
       "      <th>overlap_Qwen_Qwen3-Embedding-0.6B</th>\n",
       "      <th>overlap_Qwen_Qwen3-Embedding-4B</th>\n",
       "      <th>overlap_Lajavaness_bilingual-embedding-large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>7223</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.417834e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995036e-01</td>\n",
       "      <td>2.063487e-01</td>\n",
       "      <td>1.107199e-01</td>\n",
       "      <td>2.730872e-01</td>\n",
       "      <td>281.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>29280</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>4.113460e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.384768e-01</td>\n",
       "      <td>3.861469e-01</td>\n",
       "      <td>3.335098e-01</td>\n",
       "      <td>3.999115e-01</td>\n",
       "      <td>160.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>18918</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.848773e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269508e-01</td>\n",
       "      <td>1.124397e-01</td>\n",
       "      <td>1.308614e-01</td>\n",
       "      <td>1.124656e-01</td>\n",
       "      <td>91.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>21175</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.990553e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.296466e-01</td>\n",
       "      <td>8.616774e-02</td>\n",
       "      <td>7.558866e-02</td>\n",
       "      <td>1.153220e-01</td>\n",
       "      <td>160.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>29410</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>1.117094e-22</td>\n",
       "      <td>...</td>\n",
       "      <td>2.384258e-06</td>\n",
       "      <td>2.234147e-08</td>\n",
       "      <td>1.860428e-06</td>\n",
       "      <td>2.978196e-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>25748</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>7.143992e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010931e-01</td>\n",
       "      <td>7.774695e-02</td>\n",
       "      <td>8.953295e-02</td>\n",
       "      <td>6.518351e-02</td>\n",
       "      <td>44.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>29491</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.763240e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.396500e-04</td>\n",
       "      <td>2.683909e-04</td>\n",
       "      <td>1.017457e-03</td>\n",
       "      <td>1.224964e-03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>29394</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>4.081909e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.587220e-01</td>\n",
       "      <td>3.999348e-01</td>\n",
       "      <td>5.193721e-01</td>\n",
       "      <td>3.888977e-01</td>\n",
       "      <td>304.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>29802</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>2.475786e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.056189e-01</td>\n",
       "      <td>2.456502e-01</td>\n",
       "      <td>1.879127e-01</td>\n",
       "      <td>2.500890e-01</td>\n",
       "      <td>442.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>29424</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>8.064459e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035642e-01</td>\n",
       "      <td>1.072172e-01</td>\n",
       "      <td>1.010159e-01</td>\n",
       "      <td>1.137640e-01</td>\n",
       "      <td>265.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>24706</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.637255</td>\n",
       "      <td>3.864157e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.947252e-02</td>\n",
       "      <td>4.035954e-02</td>\n",
       "      <td>3.160499e-02</td>\n",
       "      <td>3.916452e-02</td>\n",
       "      <td>73.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>12863</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>7.823473e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.475672e-01</td>\n",
       "      <td>1.155822e-01</td>\n",
       "      <td>1.041899e-01</td>\n",
       "      <td>1.252801e-01</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>10398</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>1.193488e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.882142e-02</td>\n",
       "      <td>1.204442e-01</td>\n",
       "      <td>1.188281e-01</td>\n",
       "      <td>1.224857e-01</td>\n",
       "      <td>203.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30080</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.014716e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.578623e-01</td>\n",
       "      <td>1.907056e-01</td>\n",
       "      <td>1.774205e-01</td>\n",
       "      <td>1.739200e-01</td>\n",
       "      <td>189.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>14969</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5.280438e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.373147e-01</td>\n",
       "      <td>4.124559e-01</td>\n",
       "      <td>3.898087e-01</td>\n",
       "      <td>4.340917e-01</td>\n",
       "      <td>148.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>29361</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>9.229123e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.208358e-02</td>\n",
       "      <td>9.604856e-02</td>\n",
       "      <td>1.152261e-01</td>\n",
       "      <td>1.047415e-01</td>\n",
       "      <td>114.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>29156</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>4.105963e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.295998e-03</td>\n",
       "      <td>1.153357e-02</td>\n",
       "      <td>3.804044e-02</td>\n",
       "      <td>1.156447e-02</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>29875</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>5.557726e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.836288e-13</td>\n",
       "      <td>6.326263e-11</td>\n",
       "      <td>5.636436e-11</td>\n",
       "      <td>1.349303e-12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>29342</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.228170e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573174e-01</td>\n",
       "      <td>1.388627e-01</td>\n",
       "      <td>1.481770e-01</td>\n",
       "      <td>1.487820e-01</td>\n",
       "      <td>98.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>29568</td>\n",
       "      <td>31</td>\n",
       "      <td>https://neuronpedia.org/llama3.1-8b/31-llamasc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>4.546658e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.184041e-12</td>\n",
       "      <td>9.950038e-06</td>\n",
       "      <td>9.950127e-06</td>\n",
       "      <td>5.195972e-06</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  layer                                                url  \\\n",
       "80   7223     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "81  29280     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "82  18918     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "83  21175     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "84  29410     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "85  25748     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "86  29491     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "87  29394     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "88  29802     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "89  29424     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "90  24706     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "91  12863     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "92  10398     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "93  30080     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "94  14969     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "95  29361     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "96  29156     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "97  29875     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "98  29342     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "99  29568     31  https://neuronpedia.org/llama3.1-8b/31-llamasc...   \n",
       "\n",
       "    media_antonio  media_daniele  media_andrea  media_filippo  mean_vote  \\\n",
       "80            1.5            3.5           2.5            4.0       2.88   \n",
       "81            3.5            3.5           4.0            4.0       3.75   \n",
       "82            2.0            3.0           3.5            3.5       3.00   \n",
       "83            2.5            2.5           4.0            3.5       3.12   \n",
       "84            1.0            1.0           1.0            1.0       1.00   \n",
       "85            1.0            2.0           1.0            1.5       1.38   \n",
       "86            1.5            1.5           2.5            2.5       2.00   \n",
       "87            1.5            2.5           2.5            1.5       2.00   \n",
       "88            1.0            3.0           3.0            3.5       2.62   \n",
       "89            1.5            1.5           2.5            3.0       2.12   \n",
       "90            1.5            1.0           3.0            3.0       2.12   \n",
       "91            3.0            3.0           3.5            4.0       3.38   \n",
       "92            1.0            2.0           1.0            2.0       1.50   \n",
       "93            3.0            2.5           3.5            3.0       3.00   \n",
       "94            4.0            3.0           4.0            2.5       3.38   \n",
       "95            3.0            2.5           2.0            3.0       2.62   \n",
       "96            1.0            1.0           1.0            2.0       1.25   \n",
       "97            1.0            2.0           2.0            1.0       1.50   \n",
       "98            3.0            2.5           1.0            2.0       2.12   \n",
       "99            3.0            1.5           2.0            3.0       2.38   \n",
       "\n",
       "    score_gemini-2.0-flash  ndcg_Lajavaness/bilingual-embedding-large  ...  \\\n",
       "80                0.950000                               2.417834e-01  ...   \n",
       "81                0.941176                               4.113460e-01  ...   \n",
       "82                0.750000                               1.848773e-01  ...   \n",
       "83                1.000000                               4.990553e-02  ...   \n",
       "84                0.678571                               1.117094e-22  ...   \n",
       "85                0.675000                               7.143992e-02  ...   \n",
       "86                0.800000                               4.763240e-03  ...   \n",
       "87                0.958333                               4.081909e-01  ...   \n",
       "88                0.525000                               2.475786e-01  ...   \n",
       "89                0.825000                               8.064459e-02  ...   \n",
       "90                0.637255                               3.864157e-02  ...   \n",
       "91                0.675000                               7.823473e-02  ...   \n",
       "92                0.725000                               1.193488e-01  ...   \n",
       "93                0.916667                               2.014716e-01  ...   \n",
       "94                0.875000                               5.280438e-01  ...   \n",
       "95                0.704545                               9.229123e-02  ...   \n",
       "96                0.812500                               4.105963e-02  ...   \n",
       "97                0.625000                               5.557726e-10  ...   \n",
       "98                0.857143                               1.228170e-01  ...   \n",
       "99                0.700000                               4.546658e-10  ...   \n",
       "\n",
       "    ndcg_Qwen/Qwen3-Embedding-8B_new  ndcg_Qwen/Qwen3-Embedding-8B  \\\n",
       "80                      1.995036e-01                  2.063487e-01   \n",
       "81                      4.384768e-01                  3.861469e-01   \n",
       "82                      1.269508e-01                  1.124397e-01   \n",
       "83                      1.296466e-01                  8.616774e-02   \n",
       "84                      2.384258e-06                  2.234147e-08   \n",
       "85                      1.010931e-01                  7.774695e-02   \n",
       "86                      3.396500e-04                  2.683909e-04   \n",
       "87                      4.587220e-01                  3.999348e-01   \n",
       "88                      2.056189e-01                  2.456502e-01   \n",
       "89                      1.035642e-01                  1.072172e-01   \n",
       "90                      3.947252e-02                  4.035954e-02   \n",
       "91                      2.475672e-01                  1.155822e-01   \n",
       "92                      8.882142e-02                  1.204442e-01   \n",
       "93                      1.578623e-01                  1.907056e-01   \n",
       "94                      5.373147e-01                  4.124559e-01   \n",
       "95                      9.208358e-02                  9.604856e-02   \n",
       "96                      7.295998e-03                  1.153357e-02   \n",
       "97                      5.836288e-13                  6.326263e-11   \n",
       "98                      1.573174e-01                  1.388627e-01   \n",
       "99                      1.184041e-12                  9.950038e-06   \n",
       "\n",
       "    ndcg_Qwen/Qwen3-Embedding-0.6B  ndcg_Qwen/Qwen3-Embedding-4B  \\\n",
       "80                    1.107199e-01                  2.730872e-01   \n",
       "81                    3.335098e-01                  3.999115e-01   \n",
       "82                    1.308614e-01                  1.124656e-01   \n",
       "83                    7.558866e-02                  1.153220e-01   \n",
       "84                    1.860428e-06                  2.978196e-08   \n",
       "85                    8.953295e-02                  6.518351e-02   \n",
       "86                    1.017457e-03                  1.224964e-03   \n",
       "87                    5.193721e-01                  3.888977e-01   \n",
       "88                    1.879127e-01                  2.500890e-01   \n",
       "89                    1.010159e-01                  1.137640e-01   \n",
       "90                    3.160499e-02                  3.916452e-02   \n",
       "91                    1.041899e-01                  1.252801e-01   \n",
       "92                    1.188281e-01                  1.224857e-01   \n",
       "93                    1.774205e-01                  1.739200e-01   \n",
       "94                    3.898087e-01                  4.340917e-01   \n",
       "95                    1.152261e-01                  1.047415e-01   \n",
       "96                    3.804044e-02                  1.156447e-02   \n",
       "97                    5.636436e-11                  1.349303e-12   \n",
       "98                    1.481770e-01                  1.487820e-01   \n",
       "99                    9.950127e-06                  5.195972e-06   \n",
       "\n",
       "    overlap_Alibaba-NLP_gte-Qwen2-7B-instruct  \\\n",
       "80                                      281.0   \n",
       "81                                      160.0   \n",
       "82                                       91.0   \n",
       "83                                      160.0   \n",
       "84                                        5.0   \n",
       "85                                       44.0   \n",
       "86                                       18.0   \n",
       "87                                      304.0   \n",
       "88                                      442.0   \n",
       "89                                      265.0   \n",
       "90                                       73.0   \n",
       "91                                       58.0   \n",
       "92                                      203.0   \n",
       "93                                      189.0   \n",
       "94                                      148.0   \n",
       "95                                      114.0   \n",
       "96                                       90.0   \n",
       "97                                        6.0   \n",
       "98                                       98.0   \n",
       "99                                       14.0   \n",
       "\n",
       "    overlap_Qwen_Qwen3-Embedding-8B_new  overlap_Qwen_Qwen3-Embedding-8B  \\\n",
       "80                                262.0                            272.0   \n",
       "81                                135.0                            139.0   \n",
       "82                                 85.0                             87.0   \n",
       "83                                141.0                            131.0   \n",
       "84                                  5.0                              3.0   \n",
       "85                                 67.0                             62.0   \n",
       "86                                 33.0                             21.0   \n",
       "87                                282.0                            287.0   \n",
       "88                                430.0                            469.0   \n",
       "89                                310.0                            293.0   \n",
       "90                                 88.0                             99.0   \n",
       "91                                 60.0                             74.0   \n",
       "92                                222.0                            224.0   \n",
       "93                                238.0                            191.0   \n",
       "94                                137.0                            155.0   \n",
       "95                                123.0                            129.0   \n",
       "96                                100.0                             93.0   \n",
       "97                                 10.0                              6.0   \n",
       "98                                108.0                            105.0   \n",
       "99                                 10.0                             11.0   \n",
       "\n",
       "    overlap_Qwen_Qwen3-Embedding-0.6B  overlap_Qwen_Qwen3-Embedding-4B  \\\n",
       "80                              274.0                            282.0   \n",
       "81                              125.0                            194.0   \n",
       "82                              105.0                            120.0   \n",
       "83                              150.0                            153.0   \n",
       "84                                5.0                              5.0   \n",
       "85                               65.0                             75.0   \n",
       "86                               27.0                             18.0   \n",
       "87                              280.0                            294.0   \n",
       "88                              381.0                            468.0   \n",
       "89                              247.0                            282.0   \n",
       "90                              111.0                            101.0   \n",
       "91                               83.0                             82.0   \n",
       "92                              236.0                            228.0   \n",
       "93                              218.0                            223.0   \n",
       "94                              183.0                            139.0   \n",
       "95                              138.0                            131.0   \n",
       "96                               92.0                             89.0   \n",
       "97                               10.0                              7.0   \n",
       "98                              103.0                            106.0   \n",
       "99                               13.0                              8.0   \n",
       "\n",
       "    overlap_Lajavaness_bilingual-embedding-large  \n",
       "80                                         318.0  \n",
       "81                                         153.0  \n",
       "82                                         124.0  \n",
       "83                                         145.0  \n",
       "84                                           4.0  \n",
       "85                                          40.0  \n",
       "86                                          17.0  \n",
       "87                                         319.0  \n",
       "88                                         476.0  \n",
       "89                                         343.0  \n",
       "90                                         112.0  \n",
       "91                                          76.0  \n",
       "92                                         245.0  \n",
       "93                                         284.0  \n",
       "94                                         168.0  \n",
       "95                                         125.0  \n",
       "96                                          93.0  \n",
       "97                                          11.0  \n",
       "98                                         103.0  \n",
       "99                                          13.0  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/mmezzanzanica/project/scoring_autoint_align/3_analysis/no_reranked_ndcg_all_layers_llama_with_all_overlaps.csv')\n",
    "data[data['layer']==31]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
